# Comprehensive training configuration for the PixNerf upscaler that exposes
# every option consumed by the streamlined training configuration objects in
# `training/config.py`.

# --- PathsConfig fields ---
project: pixnerf-upscale
save_root_dir: ./runs
# Absolute or relative path to the dataset root.
ds_path: ./datasets/test_dataset
# Optional experiment metadata used when creating the run directory layout.
exp_name: pixnerf-upscale-baseline
generated_folder_name: samples
seed: 1337

# --- DatasetConfig section ---
dataset:
  high_resolution: 512
  model_resolution: 256
  resize_long_side: 0
  limit: 0
  num_workers: 24

# --- OptimizerConfig section ---
optimizer:
  batch_size: 512
  base_learning_rate: 0.005
  min_learning_rate: 0.0001
  num_epochs: 250
  optimizer_type: adamw
  beta2: 0.99
  eps: 1.0e-08
  clip_grad_norm: 1.0
  use_decay: false
  weight_decay: 0.0
  gradient_accumulation_steps: 1
  scheduler: cosine

# --- ModelConfig section ---
model:
  load_from: null
  hf_repo: stabilityai/sd-vae-ft-ema
  hf_subfolder: null
  hf_revision: main
  hf_auth_token: null
  vae_kind: kl
  weights_dtype: bf16
  sample_vaes:
    flux:
      load_from: ./weights/flux_vae.ckpt
      hf_repo: black-forest-labs/FLUX.1-schnell
      hf_subfolder: vae
      hf_revision: main
      hf_auth_token: null
      vae_kind: kl
      weights_dtype: float16
    sdxl:
      load_from: null
      hf_repo: stabilityai/sdxl-vae
      hf_subfolder: null
      hf_revision: main
      hf_auth_token: null
      vae_kind: kl
      weights_dtype: float32

# --- LossConfig section ---
loss:
  lpips_backbone: vgg

# --- LoggingConfig section ---
logging:
  use_wandb: true
  wandb_run_name: pixnerf-upscale
  global_sample_interval: 1000

# --- LatentUpscalerConfig section ---
latent_upscaler:
  model_name: swin
  model: swin
  window: 8
  depth: 6
  heads: 4
  mlp_ratio: 2.0
  liif_hidden: 256
  patch_size: 4
  blocks: 256
  nerf_blocks: 128
  groups: 4

# --- EmbeddingsConfig section ---
embeddings:
  enabled: true
  cache_dir: ./cache_vae_embeddings
  dtype: float16
  overwrite: false
  precompute_batch_size: 64
  precompute_num_workers: 4
  store_distribution: true
  vae_names:
    - flux_vae
    - sd3_vae_anime_ft

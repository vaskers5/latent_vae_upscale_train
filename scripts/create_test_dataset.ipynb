{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f08742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/kazanplova/latent_vae_upscale_train\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e072a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('clear_images_with_maniqa_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0495d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import shutil\n",
    "\n",
    "# output_root = Path(\"best_samples\")\n",
    "# output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# df_with_avg = df.assign(clip_hyper_avg=(df[\"clip_iqa\"] + df[\"hyperiqa\"]) / 2)\n",
    "# targets = {\n",
    "#     \"worst_iqa\": df_with_avg.nlargest(200, \"clip_iqa\"),\n",
    "#     \"worst_hyperiqa\": df_with_avg.nlargest(200, \"hyperiqa\"),\n",
    "#     \"worst_clip_hyper_avg\": df_with_avg.nlargest(200, \"clip_hyper_avg\"),\n",
    "# }\n",
    "\n",
    "# def copy_subset(dest_name: str, subset: pd.DataFrame) -> None:\n",
    "#     dest_dir = output_root / dest_name\n",
    "#     dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     for _, row in subset.iterrows():\n",
    "#         src_path = Path(row[\"path\"]).expanduser()\n",
    "#         if not src_path.exists():\n",
    "#             print(f\"Skipping missing file: {src_path}\")\n",
    "#             continue\n",
    "#         dest_path = dest_dir / src_path.name\n",
    "#         if dest_path.exists():\n",
    "#             dest_path = dest_dir / f\"{src_path.stem}_{row.name}{src_path.suffix}\"\n",
    "#         shutil.copy(src_path, dest_path)\n",
    "#     print(f\"Copied {len(subset)} images to {dest_dir}\")\n",
    "\n",
    "# for name, subset in targets.items():\n",
    "#     limited_subset = subset.head(min(200, len(subset)))\n",
    "#     copy_subset(name, limited_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede7744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf best_samples\n",
    "# !rm -rf worst_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a87b2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>path</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>over_limit</th>\n",
       "      <th>available_embeddings</th>\n",
       "      <th>clip_iqa</th>\n",
       "      <th>hyperiqa</th>\n",
       "      <th>clip_hyper_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>2168022.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.849434</td>\n",
       "      <td>0.261990</td>\n",
       "      <td>0.555712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38175</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>1420922.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.824737</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>0.626529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677070</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>433017.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.823075</td>\n",
       "      <td>0.417921</td>\n",
       "      <td>0.620498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579253</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>761276.0</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.820682</td>\n",
       "      <td>0.404958</td>\n",
       "      <td>0.612820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53239</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>1214512.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.819316</td>\n",
       "      <td>0.402350</td>\n",
       "      <td>0.610833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103558</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>1670892.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.621246</td>\n",
       "      <td>0.367549</td>\n",
       "      <td>0.494397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550326</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>40614.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.619190</td>\n",
       "      <td>0.369601</td>\n",
       "      <td>0.494396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468225</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>43566.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.620040</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.494395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>573177.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.611390</td>\n",
       "      <td>0.377385</td>\n",
       "      <td>0.494388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414238</th>\n",
       "      <td>validate</td>\n",
       "      <td>/data/kazanplova/latent_vae_upscale_train/unpa...</td>\n",
       "      <td>40281.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/data/kazanplova/latent_vae_upscale_train/un...</td>\n",
       "      <td>0.610077</td>\n",
       "      <td>0.378695</td>\n",
       "      <td>0.494386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173677 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage                                               path  \\\n",
       "6666    validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "38175   validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "677070  validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "579253  validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "53239   validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "...          ...                                                ...   \n",
       "103558  validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "550326  validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "468225  validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "7872    validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "414238  validate  /data/kazanplova/latent_vae_upscale_train/unpa...   \n",
       "\n",
       "        size_bytes   width  height  over_limit  \\\n",
       "6666     2168022.0  1152.0   864.0         NaN   \n",
       "38175    1420922.0  1152.0   648.0         NaN   \n",
       "677070    433017.0  1920.0  1280.0         NaN   \n",
       "579253    761276.0  2592.0  1728.0         NaN   \n",
       "53239    1214512.0  1152.0   648.0         NaN   \n",
       "...            ...     ...     ...         ...   \n",
       "103558   1670892.0  1152.0   720.0         NaN   \n",
       "550326     40614.0   265.0   400.0         NaN   \n",
       "468225     43566.0   265.0   400.0         NaN   \n",
       "7872      573177.0  1152.0   720.0         NaN   \n",
       "414238     40281.0   293.0   400.0         NaN   \n",
       "\n",
       "                                     available_embeddings  clip_iqa  hyperiqa  \\\n",
       "6666    ['/data/kazanplova/latent_vae_upscale_train/un...  0.849434  0.261990   \n",
       "38175   ['/data/kazanplova/latent_vae_upscale_train/un...  0.824737  0.428320   \n",
       "677070  ['/data/kazanplova/latent_vae_upscale_train/un...  0.823075  0.417921   \n",
       "579253  ['/data/kazanplova/latent_vae_upscale_train/un...  0.820682  0.404958   \n",
       "53239   ['/data/kazanplova/latent_vae_upscale_train/un...  0.819316  0.402350   \n",
       "...                                                   ...       ...       ...   \n",
       "103558  ['/data/kazanplova/latent_vae_upscale_train/un...  0.621246  0.367549   \n",
       "550326  ['/data/kazanplova/latent_vae_upscale_train/un...  0.619190  0.369601   \n",
       "468225  ['/data/kazanplova/latent_vae_upscale_train/un...  0.620040  0.368750   \n",
       "7872    ['/data/kazanplova/latent_vae_upscale_train/un...  0.611390  0.377385   \n",
       "414238  ['/data/kazanplova/latent_vae_upscale_train/un...  0.610077  0.378695   \n",
       "\n",
       "        clip_hyper_avg  \n",
       "6666          0.555712  \n",
       "38175         0.626529  \n",
       "677070        0.620498  \n",
       "579253        0.612820  \n",
       "53239         0.610833  \n",
       "...                ...  \n",
       "103558        0.494397  \n",
       "550326        0.494396  \n",
       "468225        0.494395  \n",
       "7872          0.494388  \n",
       "414238        0.494386  \n",
       "\n",
       "[173677 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_avg = df.assign(clip_hyper_avg=(df[\"clip_iqa\"] + df[\"hyperiqa\"]) / 2)\n",
    "count_num = 100000\n",
    "quality_df = pd.concat([\n",
    "    df_with_avg.nlargest(100000, \"clip_iqa\"),\n",
    "    df_with_avg.nlargest(100000, \"hyperiqa\"),\n",
    "    df_with_avg.nlargest(100000, \"clip_hyper_avg\"),\n",
    "], axis=0)\n",
    "quality_df.drop_duplicates(inplace=True)\n",
    "quality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1252e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_df = quality_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9375973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kazanplova/anaconda3/envs/latent_vae_train/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "from typing import Any, Iterable, Iterator, List, Optional, Tuple, Union, Set\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "embeddings_root = \"/data/kazanplova/latent_vae_upscale_train/unpacked_original_ds/full_dataset/cache_vae_embeddings\"\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _rel_after_cache_root(p: Path) -> Path:\n",
    "    \"\"\"Return path segment after 'cache_vae_embeddings/'.\"\"\"\n",
    "    parts = p.parts\n",
    "    if \"cache_vae_embeddings\" not in parts:\n",
    "        raise ValueError(f\"'cache_vae_embeddings' not in: {p}\")\n",
    "    return Path(*parts[parts.index(\"cache_vae_embeddings\") + 1:])\n",
    "\n",
    "def _new_size(w: int, h: int, long_side: int) -> Tuple[int, int]:\n",
    "    L = max(w, h)\n",
    "    if L <= long_side:\n",
    "        return w, h\n",
    "    s = long_side / float(L)\n",
    "    return max(1, int(round(w * s))), max(1, int(round(h * s)))\n",
    "\n",
    "def _resize_task(job: Tuple[str, str, int]) -> Tuple[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Worker task. Returns (src_path, error_msg_or_None).\n",
    "    Special case: if a palette image has per-palette (byte) transparency,\n",
    "    we skip it and return a 'skipped:' message.\n",
    "    \"\"\"\n",
    "    src, dst, long_side = job\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            # Turn ONLY the specific Pillow warning into an error\n",
    "            warnings.filterwarnings(\n",
    "                \"error\",\n",
    "                category=UserWarning,\n",
    "                message=r\"Palette images with Transparency expressed in bytes.*\",\n",
    "            )\n",
    "            with Image.open(src) as im:\n",
    "                # If the above warning would have been raised (i.e., such an image),\n",
    "                # it is now an exception we catch below and mark as skipped.\n",
    "                im = im.convert(\"RGB\")\n",
    "                ns = _new_size(*im.size, long_side)\n",
    "                if ns != im.size:\n",
    "                    im = im.resize(ns, Image.LANCZOS)\n",
    "                Path(dst).parent.mkdir(parents=True, exist_ok=True)\n",
    "                im.save(dst)\n",
    "        return src, None\n",
    "\n",
    "    except UserWarning:\n",
    "        # Explicitly skip these images; don't write anything to dst\n",
    "        return src, \"skipped: palette transparency (bytes)\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return src, str(e)\n",
    "\n",
    "def _run_resize(\n",
    "    jobs: List[Tuple[str, str, int]],\n",
    "    workers: Optional[int],\n",
    "    verbose: bool\n",
    ") -> Tuple[int, int, int]:\n",
    "    \"\"\"Run resize jobs in parallel. Returns (ok_count, err_count, skipped_count).\"\"\"\n",
    "    if not jobs:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    n = max(1, min(workers or cpu_count(), cpu_count()))\n",
    "    ok = err = skipped = 0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Resizing {len(jobs)} images to max {jobs[0][2]}px with {n} worker(s)...\")\n",
    "\n",
    "    with Pool(processes=n) as pool, tqdm(total=len(jobs), desc=\"Resizing images\", leave=False) as pbar:\n",
    "        for _, msg in pool.imap_unordered(_resize_task, jobs):\n",
    "            if msg is None:\n",
    "                ok += 1\n",
    "            elif isinstance(msg, str) and msg.startswith(\"skipped:\"):\n",
    "                skipped += 1\n",
    "            else:\n",
    "                err += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Resized {ok} images; skipped {skipped} (palette byte transparency); {err} failures.\")\n",
    "\n",
    "    return ok, err, skipped\n",
    "\n",
    "def _copy_embedding_task(job: Tuple[str, str, bool]) -> Tuple[str, Optional[str]]:\n",
    "    \"\"\"Copy embeddings in parallel, returning (src_path, error_or_None).\"\"\"\n",
    "    src, dst, overwrite = job\n",
    "    try:\n",
    "        dst_path = Path(dst)\n",
    "        if dst_path.exists() and not overwrite:\n",
    "            return src, \"skipped\"\n",
    "        dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(src, dst_path)\n",
    "        return src, None\n",
    "    except Exception as exc:\n",
    "        return src, str(exc)\n",
    "\n",
    "# ---------- new helpers for nested inputs ----------\n",
    "def _iter_paths_maybe_nested(items: Iterable[Any]) -> Iterator[Path]:\n",
    "    \"\"\"\n",
    "    Yield Path objects from a possibly nested iterable of paths (Path/str) or\n",
    "    iterables thereof (list/tuple/set). Non-path scalars are ignored.\n",
    "    \"\"\"\n",
    "    for x in items:\n",
    "        if isinstance(x, (list, tuple, set)):\n",
    "            # Recurse into nested iterables\n",
    "            yield from _iter_paths_maybe_nested(x)\n",
    "        else:\n",
    "            # Accept Path-like (Path/str); skip anything else quietly\n",
    "            if isinstance(x, (Path, str)):\n",
    "                yield Path(x)\n",
    "\n",
    "def _filter_by_model(paths: Iterable[Path], model_names: Optional[List[str]]) -> Iterator[Path]:\n",
    "    \"\"\"Yield only paths that contain any of the given model name substrings (if provided).\"\"\"\n",
    "    if not model_names:\n",
    "        yield from paths\n",
    "        return\n",
    "    for p in paths:\n",
    "        s = str(p)\n",
    "        if any(m in s for m in model_names):\n",
    "            yield p\n",
    "\n",
    "# ---------- main ----------\n",
    "def process_images_and_embeddings(\n",
    "    image_paths: Iterable[Union[Path, str, Iterable[Any]]],\n",
    "    embedding_paths: Iterable[Union[Path, str, Iterable[Any]]],\n",
    "    destination_root: Path,\n",
    "    *,\n",
    "    overwrite: bool = False,\n",
    "    verbose: bool = True,\n",
    "    resize_long_side: int = 1024,\n",
    "    resize_dir_name: str = \"resized_1024\",\n",
    "    resize_workers: Optional[int] = None,\n",
    "    embedding_workers: Optional[int] = None,\n",
    "    model_names : Optional[List[str]] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    - DOES NOT copy original images.\n",
    "    - Resizes images into `destination_root / resize_dir_name / ...`\n",
    "    - Copies embeddings by rewriting their prefix to `destination_root/cache_vae_embeddings/...`\n",
    "      using the segment after 'cache_vae_embeddings/'.\n",
    "    - Skips palette PNGs with transparency expressed in bytes (Pillow's specific UserWarning).\n",
    "    - Copies embeddings in parallel using multiprocessing.\n",
    "    - Supports nested (list/tuple/set) inputs for image_paths and embedding_paths.\n",
    "    \"\"\"\n",
    "    # normalize images (allow nested too, harmless if flat)\n",
    "    imgs = [Path(p) for p in tqdm(_iter_paths_maybe_nested(image_paths))]\n",
    "\n",
    "    # normalize + (optionally) filter embeddings — now supports nested input\n",
    "    flat_embs_iter = _iter_paths_maybe_nested(embedding_paths)\n",
    "    embs = list(_filter_by_model(flat_embs_iter, model_names))\n",
    "\n",
    "    if not imgs and not embs:\n",
    "        if verbose:\n",
    "            print(\"Nothing to do.\")\n",
    "        return\n",
    "\n",
    "    if resize_long_side <= 0:\n",
    "        raise ValueError(\"resize_long_side must be > 0\")\n",
    "\n",
    "    dest = Path(destination_root).expanduser().resolve()\n",
    "    dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- images: build jobs + resize ---\n",
    "    img_ok = img_err = img_skipped = 0\n",
    "    if imgs:\n",
    "        dataset_root = Path(os.path.commonpath([str(p.parent) for p in imgs]))\n",
    "        out_root = dest / resize_dir_name\n",
    "        out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        jobs: List[Tuple[str, str, int]] = []\n",
    "        for p in tqdm(imgs, desc=\"Preparing resize jobs\", leave=False):\n",
    "            rel = p.relative_to(dataset_root)\n",
    "            dst = out_root / rel\n",
    "            if dst.exists() and not overwrite:\n",
    "                continue\n",
    "            jobs.append((str(p), str(dst), int(resize_long_side)))\n",
    "\n",
    "        img_ok, img_err, img_skipped = _run_resize(jobs, resize_workers, verbose)\n",
    "\n",
    "    # --- embeddings: parallel copy via prefix rewrite (refactored) ---\n",
    "    copied = skipped = failed = 0\n",
    "    copy_jobs: List[Tuple[str, str, bool]] = []\n",
    "    seen_destinations: Set[Path] = set()\n",
    "\n",
    "    for epath in tqdm(embs, desc=\"Preparing embedding copy jobs\", leave=False):\n",
    "        try:\n",
    "            rel_path = _rel_after_cache_root(Path(epath))\n",
    "        except ValueError:\n",
    "            failed += 1\n",
    "            continue\n",
    "\n",
    "        dst_path = dest / \"cache_vae_embeddings\" / rel_path\n",
    "\n",
    "        if not overwrite and dst_path in seen_destinations:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        seen_destinations.add(dst_path)\n",
    "        copy_jobs.append((str(epath), str(dst_path), overwrite))\n",
    "\n",
    "    if copy_jobs:\n",
    "        n_workers = max(1, min(embedding_workers or cpu_count(), cpu_count()))\n",
    "        with Pool(processes=n_workers) as pool, tqdm(total=len(copy_jobs), desc=\"Copying embeddings\", leave=False) as pbar:\n",
    "            for _, msg in pool.imap_unordered(_copy_embedding_task, copy_jobs, chunksize=32):\n",
    "                if msg is None:\n",
    "                    copied += 1\n",
    "                elif msg == \"skipped\":\n",
    "                    skipped += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "                pbar.update(1)\n",
    "        if verbose:\n",
    "            print(f\"Copied embeddings with {n_workers} worker(s).\")\n",
    "\n",
    "    # --- reporting ---\n",
    "    if verbose:\n",
    "        if imgs:\n",
    "            print(\n",
    "                f\"Images -> ok: {img_ok}, skipped (palette byte transparency): {img_skipped}, errors: {img_err}. \"\n",
    "                f\"Output dir: {dest / resize_dir_name}\"\n",
    "            )\n",
    "        if embs:\n",
    "            print(f\"Embeddings -> copied: {copied}, skipped: {skipped}, failed: {failed}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3886ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6xA100_config.yaml\t\t     pretrained_weights\n",
      "LICENSE\t\t\t\t     requirements.txt\n",
      "calculate_maniqa_scores.py\t     result_cleared_df.csv\n",
      "clear_images.csv\t\t     result_cleared_df_1.csv\n",
      "clear_images.py\t\t\t     runs\n",
      "clear_images_with_maniqa_scores.csv  scripts\n",
      "configs\t\t\t\t     test_model.py\n",
      "connect_embeddings_with_images.py    train_vae.py\n",
      "data_df.csv\t\t\t     train_vae_distributed.py\n",
      "extract_data.py\t\t\t     training\n",
      "latent_upscale_quality_170k_1024px   unpacked_original_ds\n",
      "list_image_sizes.py\t\t     upscale_df_quality_170k\n",
      "load_data.sh\t\t\t     wandb\n",
      "precompute_embeddings.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf upscale_df_quality_170k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce853580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 30931.45it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 77101.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 30931.45it/s]0<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 77101.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 62695.13it/s]           \n",
      "100%|██████████| 10/10 [00:00<00:00, 62695.13it/s]           , ?it/s]\n",
      "                                                                     "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m new_dir_latent_uspcale_simple_df = \u001b[33m\"\u001b[39m\u001b[33mupscale_df_quality_170k\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mprocess_images_and_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquality_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquality_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mavailable_embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# model_names=[\"flux_vae\", \"AuraDiffusion_16ch_vae\", \"sd3_vae_anime_ft\"],\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdestination_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_dir_latent_uspcale_simple_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# manifest=quality_df,\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresize_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mflux_vae\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msd3_vae_anime_ft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 172\u001b[39m, in \u001b[36mprocess_images_and_embeddings\u001b[39m\u001b[34m(image_paths, embedding_paths, destination_root, overwrite, verbose, resize_long_side, resize_dir_name, resize_workers, embedding_workers, model_names)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epath \u001b[38;5;129;01min\u001b[39;00m tqdm(cleared_embeds, desc=\u001b[33m\"\u001b[39m\u001b[33mPreparing embedding copy jobs\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m         rel_path = _rel_after_cache_root(\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m    174\u001b[39m         failed += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/latent_vae_train/lib/python3.12/pathlib.py:1162\u001b[39m, in \u001b[36mPath.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1159\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33msupport for supplying keyword arguments to pathlib.PurePath \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1160\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mis deprecated and scheduled for removal in Python \u001b[39m\u001b[38;5;132;01m{remove}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1161\u001b[39m     warnings._deprecated(\u001b[33m\"\u001b[39m\u001b[33mpathlib.PurePath(**kwargs)\u001b[39m\u001b[33m\"\u001b[39m, msg, remove=(\u001b[32m3\u001b[39m, \u001b[32m14\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/latent_vae_train/lib/python3.12/pathlib.py:373\u001b[39m, in \u001b[36mPurePath.__init__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    371\u001b[39m             path = arg\n\u001b[32m    372\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    374\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33margument should be a str or an os.PathLike \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    375\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mobject where __fspath__ returns a str, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    376\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    377\u001b[39m         paths.append(path)\n\u001b[32m    378\u001b[39m \u001b[38;5;28mself\u001b[39m._raw_paths = paths\n",
      "\u001b[31mTypeError\u001b[39m: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'list'"
     ]
    }
   ],
   "source": [
    "\n",
    "new_dir_latent_uspcale_simple_df = \"upscale_df_quality_170k\"\n",
    "process_images_and_embeddings(\n",
    "    image_paths=quality_df[\"path\"],\n",
    "    embedding_paths=quality_df[\"available_embeddings\"].apply(eval).tolist(),\n",
    "    destination_root=new_dir_latent_uspcale_simple_df,\n",
    "    resize_workers=120,\n",
    "    embedding_workers=40,\n",
    "    model_names=[\"flux_vae\", \"sd3_vae_anime_ft\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d442f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (uncomment to run):\n",
    "# sample_paths = quality_df[\"path\"].head(10).tolist()\n",
    "# copy_images_with_embeddings(sample_paths, \"flux_vae\", Path(\"./test_dataset_subset\"), manifest=quality_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latent_vae_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
